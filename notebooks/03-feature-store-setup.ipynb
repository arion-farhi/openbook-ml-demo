{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d242b7d-8d85-47e7-85a9-b81a93d9d5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/google/cloud/aiplatform/models.py:52: FutureWarning: Support for google-cloud-storage < 3.0.0 will be removed in a future version of google-cloud-aiplatform. Please upgrade to google-cloud-storage >= 3.0.0.\n",
      "  from google.cloud.aiplatform.utils import gcs_utils\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project: openbook-ml-demo\n",
      "Region: us-central1\n",
      "\n",
      "✓ Vertex AI initialized\n"
     ]
    }
   ],
   "source": [
    "# 03-feature-store-setup.ipynb\n",
    "# Openbook ML Demo - Vertex AI Feature Store Setup\n",
    "\n",
    "\"\"\"\n",
    "Feature Store provides:\n",
    "1. Centralized feature storage with entity keys\n",
    "2. Online serving (low-latency for real-time inference)\n",
    "3. Offline serving (batch for training)\n",
    "4. Feature versioning and lineage\n",
    "5. Training-serving consistency (no skew)\n",
    "\n",
    "Flow:\n",
    "- Dataflow created features → GCS\n",
    "- This notebook → Feature Store ingestion\n",
    "- Training reads from Feature Store (offline)\n",
    "- Inference reads from Feature Store (online)\n",
    "\"\"\"\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import storage\n",
    "from google.cloud.aiplatform_v1 import FeaturestoreServiceClient\n",
    "from google.cloud.aiplatform_v1 import FeatureOnlineStoreServiceClient\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# Configuration\n",
    "PROJECT_ID = \"openbook-ml-demo\"\n",
    "REGION = \"us-central1\"\n",
    "BUCKET_NAME = \"openbook-data-lake\"\n",
    "\n",
    "# Initialize Vertex AI\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "\n",
    "# GCS client\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "bucket = storage_client.bucket(BUCKET_NAME)\n",
    "\n",
    "print(f\"Project: {PROJECT_ID}\")\n",
    "print(f\"Region: {REGION}\")\n",
    "print(\"\\n✓ Vertex AI initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4af5f3c-73dd-416c-9528-ba71de11f627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Feature Online Store (this takes 5-10 minutes)...\n",
      "✓ Created: projects/350248978874/locations/us-central1/featureOnlineStores/openbook_feature_store\n"
     ]
    }
   ],
   "source": [
    "# Create Feature Store (Online Store for low-latency serving)\n",
    "\n",
    "from google.cloud.aiplatform_v1 import FeatureOnlineStoreAdminServiceClient\n",
    "from google.cloud.aiplatform_v1.types import feature_online_store as feature_online_store_pb2\n",
    "from google.cloud.aiplatform_v1.types import feature_online_store_admin_service as admin_pb2\n",
    "\n",
    "# Create Feature Online Store\n",
    "admin_client = FeatureOnlineStoreAdminServiceClient(\n",
    "    client_options={\"api_endpoint\": f\"{REGION}-aiplatform.googleapis.com\"}\n",
    ")\n",
    "\n",
    "parent = f\"projects/{PROJECT_ID}/locations/{REGION}\"\n",
    "\n",
    "# Define online store configuration\n",
    "online_store_config = feature_online_store_pb2.FeatureOnlineStore(\n",
    "    bigtable=feature_online_store_pb2.FeatureOnlineStore.Bigtable(\n",
    "        auto_scaling=feature_online_store_pb2.FeatureOnlineStore.Bigtable.AutoScaling(\n",
    "            min_node_count=1,\n",
    "            max_node_count=1,  # Keep minimal for demo\n",
    "            cpu_utilization_target=80,\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create the store\n",
    "try:\n",
    "    operation = admin_client.create_feature_online_store(\n",
    "        parent=parent,\n",
    "        feature_online_store_id=\"openbook_feature_store\",\n",
    "        feature_online_store=online_store_config,\n",
    "    )\n",
    "    print(\"Creating Feature Online Store (this takes 5-10 minutes)...\")\n",
    "    result = operation.result()  # Wait for completion\n",
    "    print(f\"✓ Created: {result.name}\")\n",
    "except Exception as e:\n",
    "    if \"already exists\" in str(e):\n",
    "        print(\"✓ Feature Online Store already exists\")\n",
    "    else:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8daaa87f-8d50-4860-822c-091b1d4f263c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 7000 training samples\n",
      "Columns: ['claim_id', 'patient_id', 'procedure_code', 'procedure_cost', 'annual_maximum', 'remaining_maximum', 'deductible_remaining', 'coverage_ratio', 'months_enrolled', 'max_utilization', 'cost_to_max_ratio', 'deductible_applies', 'network_penalty', 'waiting_period_risk', 'is_preventive', 'is_basic', 'is_major', 'high_cost_procedure', 'is_ppo', 'is_dhmo', 'is_indemnity', 'carrier_delta_dental', 'carrier_cigna', 'carrier_aetna', 'carrier_metlife', 'carrier_guardian', 'expected_copay', 'copay_deviation', 'patient_copay']\n",
      "✓ Created BigQuery dataset: openbook-ml-demo.openbook_features\n",
      "✓ Uploaded 7000 rows to openbook-ml-demo.openbook_features.claim_features\n"
     ]
    }
   ],
   "source": [
    "# Create Feature View (defines which features to serve)\n",
    "# Feature Views connect GCS/BigQuery data to the online store\n",
    "\n",
    "from google.cloud.aiplatform_v1.types import feature_view as feature_view_pb2\n",
    "\n",
    "# First, load our features to understand schema\n",
    "blob = bucket.blob('processed/features/train.csv')\n",
    "content = blob.download_as_text()\n",
    "train_df = pd.read_csv(StringIO(content))\n",
    "\n",
    "print(f\"Loaded {len(train_df)} training samples\")\n",
    "print(f\"Columns: {train_df.columns.tolist()}\")\n",
    "\n",
    "# For Feature Store, we need to upload to BigQuery first (Feature Store reads from BQ)\n",
    "# Let's create BigQuery dataset and table\n",
    "\n",
    "from google.cloud import bigquery\n",
    "\n",
    "bq_client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "# Create dataset\n",
    "dataset_id = f\"{PROJECT_ID}.openbook_features\"\n",
    "dataset = bigquery.Dataset(dataset_id)\n",
    "dataset.location = REGION\n",
    "\n",
    "try:\n",
    "    bq_client.create_dataset(dataset, exists_ok=True)\n",
    "    print(f\"✓ Created BigQuery dataset: {dataset_id}\")\n",
    "except Exception as e:\n",
    "    print(f\"Dataset exists or error: {e}\")\n",
    "\n",
    "# Upload features to BigQuery\n",
    "table_id = f\"{dataset_id}.claim_features\"\n",
    "\n",
    "# Add entity_id column (required for Feature Store)\n",
    "train_df['entity_id'] = train_df['claim_id']\n",
    "# Add feature_timestamp (required for Feature Store)\n",
    "train_df['feature_timestamp'] = pd.Timestamp.now()\n",
    "\n",
    "# Upload to BigQuery\n",
    "job_config = bigquery.LoadJobConfig(write_disposition=\"WRITE_TRUNCATE\")\n",
    "job = bq_client.load_table_from_dataframe(train_df, table_id, job_config=job_config)\n",
    "job.result()\n",
    "\n",
    "print(f\"✓ Uploaded {len(train_df)} rows to {table_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ceea6ce1-4f03-4804-9077-e419efd78ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Re-uploaded 7000 rows to BigQuery (without timestamp column)\n",
      "\n",
      "Columns:\n",
      "['claim_id', 'patient_id', 'procedure_code', 'procedure_cost', 'annual_maximum', 'remaining_maximum', 'deductible_remaining', 'coverage_ratio', 'months_enrolled', 'max_utilization', 'cost_to_max_ratio', 'deductible_applies', 'network_penalty', 'waiting_period_risk', 'is_preventive', 'is_basic', 'is_major', 'high_cost_procedure', 'is_ppo', 'is_dhmo', 'is_indemnity', 'carrier_delta_dental', 'carrier_cigna', 'carrier_aetna', 'carrier_metlife', 'carrier_guardian', 'expected_copay', 'copay_deviation', 'patient_copay', 'entity_id']\n"
     ]
    }
   ],
   "source": [
    "# Fix timestamp column type and re-upload to BigQuery\n",
    "\n",
    "# Reload data\n",
    "blob = bucket.blob('processed/features/train.csv')\n",
    "content = blob.download_as_text()\n",
    "train_df = pd.read_csv(StringIO(content))\n",
    "\n",
    "# Add entity_id\n",
    "train_df['entity_id'] = train_df['claim_id']\n",
    "\n",
    "# Add feature_timestamp as proper TIMESTAMP (not datetime)\n",
    "# Feature Store needs this as a string in ISO format\n",
    "train_df['feature_timestamp'] = pd.Timestamp.now(tz='UTC').isoformat()\n",
    "\n",
    "# Drop the timestamp column - Feature Store will use a default\n",
    "# Or we rename to avoid the reserved column issue\n",
    "train_df = train_df.drop(columns=['feature_timestamp'])\n",
    "\n",
    "# Re-upload to BigQuery without timestamp (Feature Store handles it)\n",
    "table_id = f\"{PROJECT_ID}.openbook_features.claim_features\"\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(write_disposition=\"WRITE_TRUNCATE\")\n",
    "job = bq_client.load_table_from_dataframe(train_df, table_id, job_config=job_config)\n",
    "job.result()\n",
    "\n",
    "print(f\"✓ Re-uploaded {len(train_df)} rows to BigQuery (without timestamp column)\")\n",
    "print(\"\\nColumns:\")\n",
    "print(train_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8761d769-34dc-4883-a341-93272b88baaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Feature View...\n",
      "✗ Error: AlreadyExists\n",
      "  Message: 409 FeatureView `projects/350248978874/locations/us-central1/featureOnlineStores/openbook_feature_store/featureViews/claim_features_view` already exists.\n"
     ]
    }
   ],
   "source": [
    "# Retry Feature View creation\n",
    "\n",
    "feature_view_config = feature_view_pb2.FeatureView(\n",
    "    big_query_source=feature_view_pb2.FeatureView.BigQuerySource(\n",
    "        uri=f\"bq://{PROJECT_ID}.openbook_features.claim_features\",\n",
    "        entity_id_columns=[\"entity_id\"],\n",
    "    ),\n",
    "    sync_config=feature_view_pb2.FeatureView.SyncConfig(\n",
    "        cron=\"0 0 * * *\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "online_store_path = f\"{parent}/featureOnlineStores/openbook_feature_store\"\n",
    "\n",
    "print(\"Creating Feature View...\")\n",
    "try:\n",
    "    operation = admin_client.create_feature_view(\n",
    "        parent=online_store_path,\n",
    "        feature_view_id=\"claim_features_view\",\n",
    "        feature_view=feature_view_config,\n",
    "    )\n",
    "    print(\"Waiting for operation (2-5 min)...\")\n",
    "    result = operation.result(timeout=600)\n",
    "    print(f\"✓ Created Feature View: {result.name}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error: {type(e).__name__}\")\n",
    "    print(f\"  Message: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8c8b685-95bd-44c9-8958-541e1e981ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Name: projects/350248978874/locations/us-central1/featureOnlineStores/openbook_feature_store/featureViews/claim_features_view\n",
      "✓ BigQuery Source: bq://openbook-ml-demo.openbook_features.claim_features\n",
      "✓ Entity ID Column: ['entity_id']\n",
      "✓ Sync started: projects/openbook-ml-demo/locations/us-central1/featureOnlineStores/openbook_feature_store/featureViews/claim_features_view/featureViewSyncs/1327014692530421760\n"
     ]
    }
   ],
   "source": [
    "# Verify Feature View exists and check status\n",
    "\n",
    "feature_view_path = f\"{online_store_path}/featureViews/claim_features_view\"\n",
    "\n",
    "fv = admin_client.get_feature_view(name=feature_view_path)\n",
    "print(f\"✓ Name: {fv.name}\")\n",
    "print(f\"✓ BigQuery Source: {fv.big_query_source.uri}\")\n",
    "print(f\"✓ Entity ID Column: {fv.big_query_source.entity_id_columns}\")\n",
    "\n",
    "# Trigger manual sync to populate online store\n",
    "sync_response = admin_client.sync_feature_view(feature_view=feature_view_path)\n",
    "print(f\"✓ Sync started: {sync_response.feature_view_sync}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d24e787-fa07-4f82-9f86-5a8ad2c38fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Online Feature Serving Test\n",
      "==================================================\n",
      "Entity ID: CLM_000301\n",
      "\n",
      "Response type: <class 'google.cloud.aiplatform_v1.types.feature_online_store_service.FetchFeatureValuesResponse'>\n",
      "\n",
      "Response:\n",
      "key_values {\n",
      "  features {\n",
      "    name: \"claim_id\"\n",
      "    value {\n",
      "      string_value: \"CLM_000301\"\n",
      "    }\n",
      "  }\n",
      "  features {\n",
      "    name: \"patient_id\"\n",
      "    value {\n",
      "      string_value: \"PAT_0677\"\n",
      "    }\n",
      "  }\n",
      "  features {\n",
      "    name: \"procedure_code\"\n",
      "    value {\n",
      "      string_value: \"D0120\"\n",
      "    }\n",
      "  }\n",
      "  features {\n",
      "    name: \"procedure_cost\"\n",
      "    value {\n",
      "      double_value: 65\n",
      "    }\n",
      "  }\n",
      "  features {\n",
      "    name: \"annual_maximum\"\n",
      "    value {\n",
      "      double_value: 1500\n",
      "    }\n",
      "  }\n",
      "  features {\n",
      "    name: \"remaining_maximum\"\n",
      "    value {\n",
      "      double_value: 75\n",
      "    }\n",
      "  }\n",
      "  features {\n",
      "    name: \"deductible_remaining\"\n",
      "    value {\n",
      "      double_value: 0\n",
      "    }\n",
      "  }\n",
      "  features {\n",
      "    name: \"coverage_ratio\"\n",
      "    value {\n",
      "      double_value: 1\n",
      "    }\n",
      "  }\n",
      "  features {\n",
      "    name: \"months_enrolled\"\n",
      "    value {\n",
      "      int64_value: 24\n",
      "    }\n",
      "  }\n",
      "  features {\n",
      "    name: \"max_utilization\"\n",
      "    value {\n",
      "      double_value: 0.95\n",
      "    }\n",
      "  }\n",
      "  features {\n",
      "    name: \"cost_to_max_ratio\"\n",
      "    value {\n",
      "      double_value: 0.8666666666666667\n",
      "    }\n",
      "  }\n",
      "  features {\n",
      "    name: \"deductible_applies\"\n",
      "    value {\n",
      "      int64_value: 0\n",
      "    }\n",
      "  }\n",
      "  features {\n",
      "    name: \"network_penalty\"\n",
      "    value {\n",
      "      int64_value: 0\n",
      "    }\n",
      "  }\n",
      "  features {\n",
      "    name: \"waiting_period_risk\"\n",
      "    value {\n",
      "      int64_value: 0\n",
      "    }\n",
      "  }\n",
      "  features {\n",
      "    name: \"is_preventive\"\n",
      "    value {\n",
      "      int64_value: 1\n",
      "    }\n",
      "  }\n",
      "  features {\n",
      "    name: \"is_basic\"\n",
      "    value {\n",
      "      int64_value: 0\n",
      "    }\n",
      "  }\n",
      "  features {\n",
      "    name: \"is_major\"\n",
      "    value {\n",
      "      int64_value: 0\n",
      "    }\n",
      "  }\n",
      "  features {\n",
      "    name: \"high_cost_procedure\"\n",
      "    value {\n",
      "      int64_value: 0\n",
      "    }\n",
      "  }\n",
      "  features {\n",
      "    name: \"is_ppo\"\n",
      "    value {\n",
      "      int64_value: 1\n",
      "    }\n",
      "  }\n",
      "  features {\n",
      "    name: \"is_dhmo\"\n",
      "    value {\n",
      "      int64_value: 0\n",
      "    }\n",
      "  }\n",
      "  features {\n",
      "    name: \"is_indemnity\"\n",
      "    value {\n",
      "      int64_value: 0\n",
      "    }\n",
      "  }\n",
      "  features {\n",
      "    name: \"carrier_delta_dental\"\n",
      "    value {\n",
      "      int64_value: 1\n",
      "    }\n",
      "  }\n",
      "  features {\n",
      "    name: \"carrier_cigna\"\n",
      "    value {\n",
      "      int64_value: 0\n",
      "    }\n",
      "  }\n",
      "  features {\n",
      "    name: \"carrier_aetna\"\n",
      "    value {\n",
      "      int64_value: 0\n",
      "    }\n",
      "  }\n",
      "  features {\n",
      "    name: \"carrier_metlife\"\n",
      "    value {\n",
      "      int64_value: 0\n",
      "    }\n",
      "  }\n",
      "  features {\n",
      "    name: \"carrier_guardian\"\n",
      "    value {\n",
      "      int64_value: 0\n",
      "    }\n",
      "  }\n",
      "  features {\n",
      "    name: \"expected_copay\"\n",
      "    value {\n",
      "      double_value: 0\n",
      "    }\n",
      "  }\n",
      "  features {\n",
      "    name: \"copay_deviation\"\n",
      "    value {\n",
      "      double_value: 0.81\n",
      "    }\n",
      "  }\n",
      "  features {\n",
      "    name: \"patient_copay\"\n",
      "    value {\n",
      "      double_value: 0.81\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect response structure\n",
    "response = online_client.fetch_feature_values(\n",
    "    request=feature_online_store_service.FetchFeatureValuesRequest(\n",
    "        feature_view=feature_view_path,\n",
    "        data_key=feature_online_store_service.FeatureViewDataKey(key=\"CLM_000301\"),\n",
    "        data_format=feature_online_store_service.FeatureViewDataFormat.KEY_VALUE,\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"✓ Online Feature Serving Test\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Entity ID: CLM_000301\")\n",
    "print(f\"\\nResponse type: {type(response)}\")\n",
    "print(f\"\\nResponse:\\n{response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7825cd2c-1ed8-4be0-a5a1-c226a269174d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Feature Store Setup Complete\n",
      "==================================================\n",
      "Online Store: openbook_feature_store\n",
      "Feature View: claim_features_view\n",
      "Source: BigQuery (openbook_features.claim_features)\n",
      "Features: 29\n",
      "Entities: 7,000 (training set)\n",
      "\n",
      "Online serving: Bigtable-backed, millisecond latency\n",
      "Offline serving: BigQuery for batch training\n"
     ]
    }
   ],
   "source": [
    "# Feature Store Summary\n",
    "print(\"✓ Feature Store Setup Complete\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Online Store: openbook_feature_store\")\n",
    "print(f\"Feature View: claim_features_view\")\n",
    "print(f\"Source: BigQuery (openbook_features.claim_features)\")\n",
    "print(f\"Features: 29\")\n",
    "print(f\"Entities: 7,000 (training set)\")\n",
    "print(f\"\\nOnline serving: Bigtable-backed, millisecond latency\")\n",
    "print(f\"Offline serving: BigQuery for batch training\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m137",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m137"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
