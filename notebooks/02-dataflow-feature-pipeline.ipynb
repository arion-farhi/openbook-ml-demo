{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68e3b2f1-fd70-4199-89ff-aa78a303c2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATAFLOW JOB 1: Training Data Preparation\n",
      "==================================================\n",
      "Project: openbook-ml-demo\n",
      "Region: us-central1\n",
      "Input:  gs://openbook-data-lake/raw/claims/\n",
      "Output: gs://openbook-data-lake/processed/features/\n",
      "\n",
      "✓ Configuration set\n"
     ]
    }
   ],
   "source": [
    "# 02-dataflow-feature-pipeline.ipynb\n",
    "# Openbook ML Demo - Dataflow Feature Engineering Pipeline\n",
    "\n",
    "\"\"\"\n",
    "=============================================================================\n",
    "DATAFLOW IN THIS PROJECT - TWO SEPARATE JOBS\n",
    "=============================================================================\n",
    "\n",
    "JOB 1: Training Data Preparation (THIS NOTEBOOK)\n",
    "-------------------------------------------------\n",
    "When: Run once to prepare training data (or periodically when new claims arrive)\n",
    "Input: Raw claims from GCS (gs://openbook-data-lake/raw/claims/)\n",
    "Process: \n",
    "    - Engineer features from raw claims\n",
    "    - Encode categorical variables\n",
    "    - Create procedure embeddings\n",
    "    - Aggregate patient-level features\n",
    "Output: Processed features to GCS (gs://openbook-data-lake/processed/features/)\n",
    "Then: Features feed into model training (notebook 04)\n",
    "\n",
    "\n",
    "JOB 2: Batch Inference (NOTEBOOK 08 - deployment)\n",
    "-------------------------------------------------\n",
    "When: On-demand when dental office submits patients\n",
    "Input: Batch of patients needing copay predictions\n",
    "Process:\n",
    "    - Fetch features from Feature Store\n",
    "    - Run model predictions in parallel\n",
    "    - Generate treatment plans via LLM\n",
    "Output: Predicted copays for all patients\n",
    "Scale: \n",
    "    - Production: 100 patients via Dataflow workers\n",
    "    - Demo: 5 patients (simplified)\n",
    "\n",
    "=============================================================================\n",
    "THIS NOTEBOOK: We write and submit JOB 1 to Dataflow service\n",
    "=============================================================================\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from google.cloud import storage\n",
    "\n",
    "# Configuration\n",
    "PROJECT_ID = \"openbook-ml-demo\"\n",
    "REGION = \"us-central1\"\n",
    "BUCKET_NAME = \"openbook-data-lake\"\n",
    "\n",
    "print(\"DATAFLOW JOB 1: Training Data Preparation\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Project: {PROJECT_ID}\")\n",
    "print(f\"Region: {REGION}\")\n",
    "print(f\"Input:  gs://{BUCKET_NAME}/raw/claims/\")\n",
    "print(f\"Output: gs://{BUCKET_NAME}/processed/features/\")\n",
    "print(\"\\n✓ Configuration set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cefb64f4-52d0-43f8-95a0-62019f5155ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "client = storage.Client(project=PROJECT_ID)\n",
    "bucket = client.bucket(BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b4f6f2c-946d-43c6-a348-cc187cebd765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Dataflow pipeline script created\n",
      "✓ Uploaded to gs://openbook-data-lake/pipeline/dataflow_feature_pipeline.py\n",
      "\n",
      "Features engineered:\n",
      "  - coverage_ratio: Coverage % for procedure category\n",
      "  - max_utilization: % of annual max already used\n",
      "  - cost_to_max_ratio: Will procedure exhaust remaining max?\n",
      "  - deductible_applies: Binary flag\n",
      "  - network_penalty: Out-of-network indicator\n",
      "  - waiting_period_risk: New enrollee flag\n",
      "  - expected_copay: Naive formula calculation\n",
      "  - copay_deviation: Actual - Expected (what model learns)\n"
     ]
    }
   ],
   "source": [
    "# Write Dataflow pipeline script to file\n",
    "# This script will be submitted to Dataflow service (runs on GCP workers)\n",
    "\n",
    "dataflow_script = '''\n",
    "import apache_beam as beam\n",
    "from apache_beam.options.pipeline_options import PipelineOptions, StandardOptions, GoogleCloudOptions, SetupOptions\n",
    "import json\n",
    "import csv\n",
    "from io import StringIO\n",
    "\n",
    "# ============================================================================\n",
    "# FEATURE ENGINEERING TRANSFORMS\n",
    "# ============================================================================\n",
    "\n",
    "class ParseClaim(beam.DoFn):\n",
    "    \"\"\"Parse CSV row into claim dictionary\"\"\"\n",
    "    def __init__(self, header):\n",
    "        self.header = header\n",
    "    \n",
    "    def process(self, row):\n",
    "        reader = csv.reader(StringIO(row))\n",
    "        values = next(reader)\n",
    "        if values[0] == 'claim_id':  # Skip header\n",
    "            return\n",
    "        yield dict(zip(self.header, values))\n",
    "\n",
    "\n",
    "class EngineerFeatures(beam.DoFn):\n",
    "    \"\"\"Engineer features for each claim\"\"\"\n",
    "    \n",
    "    def process(self, claim):\n",
    "        # Numeric conversions\n",
    "        claim['procedure_cost'] = float(claim['procedure_cost'])\n",
    "        claim['charged_amount'] = float(claim['charged_amount'])\n",
    "        claim['insurance_paid'] = float(claim['insurance_paid'])\n",
    "        claim['patient_copay'] = float(claim['patient_copay'])\n",
    "        claim['annual_maximum'] = float(claim['annual_maximum'])\n",
    "        claim['remaining_maximum'] = float(claim['remaining_maximum'])\n",
    "        claim['deductible_remaining'] = float(claim['deductible_remaining'])\n",
    "        claim['preventive_coverage'] = float(claim['preventive_coverage'])\n",
    "        claim['basic_coverage'] = float(claim['basic_coverage'])\n",
    "        claim['major_coverage'] = float(claim['major_coverage'])\n",
    "        claim['months_enrolled'] = int(claim['months_enrolled'])\n",
    "        claim['is_in_network'] = claim['is_in_network'] == 'True'\n",
    "        \n",
    "        # === ENGINEERED FEATURES ===\n",
    "        \n",
    "        # 1. Coverage ratio for this procedure category\n",
    "        category = claim['procedure_category']\n",
    "        if category == 'preventive':\n",
    "            claim['coverage_ratio'] = claim['preventive_coverage'] / 100\n",
    "        elif category == 'basic':\n",
    "            claim['coverage_ratio'] = claim['basic_coverage'] / 100\n",
    "        else:\n",
    "            claim['coverage_ratio'] = claim['major_coverage'] / 100\n",
    "        \n",
    "        # 2. Max utilization ratio (how much of annual max is used)\n",
    "        if claim['annual_maximum'] > 0:\n",
    "            claim['max_utilization'] = 1 - (claim['remaining_maximum'] / claim['annual_maximum'])\n",
    "        else:\n",
    "            claim['max_utilization'] = 0  # DHMO has no max\n",
    "        \n",
    "        # 3. Cost to remaining max ratio (will this exhaust the max?)\n",
    "        if claim['remaining_maximum'] > 0:\n",
    "            claim['cost_to_max_ratio'] = claim['procedure_cost'] / claim['remaining_maximum']\n",
    "        else:\n",
    "            claim['cost_to_max_ratio'] = 999  # Max already exhausted\n",
    "        \n",
    "        # 4. Deductible impact\n",
    "        claim['deductible_applies'] = 1 if claim['deductible_remaining'] > 0 else 0\n",
    "        \n",
    "        # 5. Network penalty indicator\n",
    "        claim['network_penalty'] = 0 if claim['is_in_network'] else 1\n",
    "        \n",
    "        # 6. Waiting period risk (for newer enrollees)\n",
    "        claim['waiting_period_risk'] = 1 if claim['months_enrolled'] < 12 else 0\n",
    "        \n",
    "        # 7. Procedure category encoding (one-hot)\n",
    "        claim['is_preventive'] = 1 if category == 'preventive' else 0\n",
    "        claim['is_basic'] = 1 if category == 'basic' else 0\n",
    "        claim['is_major'] = 1 if category == 'major' else 0\n",
    "        \n",
    "        # 8. High cost flag\n",
    "        claim['high_cost_procedure'] = 1 if claim['procedure_cost'] > 500 else 0\n",
    "        \n",
    "        # 9. Plan type encoding\n",
    "        claim['is_ppo'] = 1 if claim['plan_type'] == 'PPO' else 0\n",
    "        claim['is_dhmo'] = 1 if claim['plan_type'] == 'DHMO' else 0\n",
    "        claim['is_indemnity'] = 1 if claim['plan_type'] == 'Indemnity' else 0\n",
    "        \n",
    "        # 10. Carrier encoding\n",
    "        carriers = ['Delta Dental', 'Cigna', 'Aetna', 'MetLife', 'Guardian']\n",
    "        for c in carriers:\n",
    "            claim[f'carrier_{c.lower().replace(\" \", \"_\")}'] = 1 if claim['carrier'] == c else 0\n",
    "        \n",
    "        # 11. Expected copay (naive formula - model learns deviation from this)\n",
    "        expected_insurance = claim['procedure_cost'] * claim['coverage_ratio']\n",
    "        if claim['annual_maximum'] > 0:\n",
    "            expected_insurance = min(expected_insurance, claim['remaining_maximum'])\n",
    "        claim['expected_copay'] = claim['procedure_cost'] - expected_insurance + claim['deductible_remaining']\n",
    "        \n",
    "        # 12. Target: Actual copay deviation from expected\n",
    "        claim['copay_deviation'] = claim['patient_copay'] - claim['expected_copay']\n",
    "        \n",
    "        yield claim\n",
    "\n",
    "\n",
    "class FormatOutput(beam.DoFn):\n",
    "    \"\"\"Format features as CSV row for output\"\"\"\n",
    "    \n",
    "    FEATURE_COLUMNS = [\n",
    "        'claim_id', 'patient_id', 'procedure_code',\n",
    "        # Raw features\n",
    "        'procedure_cost', 'annual_maximum', 'remaining_maximum',\n",
    "        'deductible_remaining', 'coverage_ratio', 'months_enrolled',\n",
    "        # Engineered features\n",
    "        'max_utilization', 'cost_to_max_ratio', 'deductible_applies',\n",
    "        'network_penalty', 'waiting_period_risk',\n",
    "        'is_preventive', 'is_basic', 'is_major',\n",
    "        'high_cost_procedure', 'is_ppo', 'is_dhmo', 'is_indemnity',\n",
    "        'carrier_delta_dental', 'carrier_cigna', 'carrier_aetna',\n",
    "        'carrier_metlife', 'carrier_guardian',\n",
    "        'expected_copay', 'copay_deviation',\n",
    "        # Target\n",
    "        'patient_copay'\n",
    "    ]\n",
    "    \n",
    "    def process(self, claim):\n",
    "        values = [str(claim.get(col, '')) for col in self.FEATURE_COLUMNS]\n",
    "        yield ','.join(values)\n",
    "\n",
    "\n",
    "def run_pipeline(argv=None):\n",
    "    \"\"\"Main pipeline execution\"\"\"\n",
    "    \n",
    "    # Pipeline options\n",
    "    options = PipelineOptions(argv)\n",
    "    gcp_options = options.view_as(GoogleCloudOptions)\n",
    "    gcp_options.project = 'openbook-ml-demo'\n",
    "    gcp_options.region = 'us-central1'\n",
    "    gcp_options.job_name = 'openbook-feature-engineering'\n",
    "    gcp_options.staging_location = 'gs://openbook-data-lake/staging'\n",
    "    gcp_options.temp_location = 'gs://openbook-data-lake/temp'\n",
    "    \n",
    "    options.view_as(StandardOptions).runner = 'DataflowRunner'\n",
    "    options.view_as(SetupOptions).save_main_session = True\n",
    "    \n",
    "    # CSV header\n",
    "    header = [\n",
    "        'claim_id', 'patient_id', 'procedure_code', 'procedure_category',\n",
    "        'claim_date', 'plan_id', 'carrier', 'plan_type', 'is_in_network',\n",
    "        'annual_maximum', 'remaining_maximum', 'deductible_remaining',\n",
    "        'preventive_coverage', 'basic_coverage', 'major_coverage',\n",
    "        'months_enrolled', 'procedure_cost', 'charged_amount',\n",
    "        'insurance_paid', 'patient_copay', 'claim_status'\n",
    "    ]\n",
    "    \n",
    "    # Build and run pipeline\n",
    "    with beam.Pipeline(options=options) as p:\n",
    "        # Read raw claims\n",
    "        claims = (\n",
    "            p\n",
    "            | 'ReadClaims' >> beam.io.ReadFromText('gs://openbook-data-lake/raw/claims/claims.csv')\n",
    "            | 'ParseCSV' >> beam.ParDo(ParseClaim(header))\n",
    "            | 'EngineerFeatures' >> beam.ParDo(EngineerFeatures())\n",
    "            | 'FormatOutput' >> beam.ParDo(FormatOutput())\n",
    "        )\n",
    "        \n",
    "        # Write processed features\n",
    "        claims | 'WriteFeatures' >> beam.io.WriteToText(\n",
    "            'gs://openbook-data-lake/processed/features/features',\n",
    "            file_name_suffix='.csv',\n",
    "            header=','.join(FormatOutput.FEATURE_COLUMNS)\n",
    "        )\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_pipeline()\n",
    "'''\n",
    "\n",
    "# Save to file\n",
    "with open('dataflow_feature_pipeline.py', 'w') as f:\n",
    "    f.write(dataflow_script)\n",
    "\n",
    "# Upload to GCS\n",
    "blob = bucket.blob('pipeline/dataflow_feature_pipeline.py')\n",
    "blob.upload_from_filename('dataflow_feature_pipeline.py')\n",
    "\n",
    "print(\"✓ Dataflow pipeline script created\")\n",
    "print(\"✓ Uploaded to gs://openbook-data-lake/pipeline/dataflow_feature_pipeline.py\")\n",
    "print(\"\\nFeatures engineered:\")\n",
    "print(\"  - coverage_ratio: Coverage % for procedure category\")\n",
    "print(\"  - max_utilization: % of annual max already used\")\n",
    "print(\"  - cost_to_max_ratio: Will procedure exhaust remaining max?\")\n",
    "print(\"  - deductible_applies: Binary flag\")\n",
    "print(\"  - network_penalty: Out-of-network indicator\")\n",
    "print(\"  - waiting_period_risk: New enrollee flag\")\n",
    "print(\"  - expected_copay: Naive formula calculation\")\n",
    "print(\"  - copay_deviation: Actual - Expected (what model learns)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b7aad3b-b634-490a-b741-d5fa4c5262b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting Dataflow job...\n",
      "==================================================\n",
      "/opt/conda/lib/python3.10/site-packages/google/api_core/_python_version_support.py:266: FutureWarning: You are using a Python version (3.10.19) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "WARNING:apache_beam.options.pipeline_options:Bucket specified in temp_location has soft-delete policy enabled. To avoid being billed for unnecessary storage costs, turn off the soft delete feature on buckets that your Dataflow jobs use for temporary and staging storage. For more information, see https://cloud.google.com/storage/docs/use-soft-delete#remove-soft-delete-policy.\n",
      "WARNING:apache_beam.options.pipeline_options:Bucket specified in staging_location has soft-delete policy enabled. To avoid being billed for unnecessary storage costs, turn off the soft delete feature on buckets that your Dataflow jobs use for temporary and staging storage. For more information, see https://cloud.google.com/storage/docs/use-soft-delete#remove-soft-delete-policy.\n",
      "WARNING:apache_beam.options.pipeline_options:Bucket specified in temp_location has soft-delete policy enabled. To avoid being billed for unnecessary storage costs, turn off the soft delete feature on buckets that your Dataflow jobs use for temporary and staging storage. For more information, see https://cloud.google.com/storage/docs/use-soft-delete#remove-soft-delete-policy.\n",
      "WARNING:apache_beam.options.pipeline_options:Bucket specified in staging_location has soft-delete policy enabled. To avoid being billed for unnecessary storage costs, turn off the soft delete feature on buckets that your Dataflow jobs use for temporary and staging storage. For more information, see https://cloud.google.com/storage/docs/use-soft-delete#remove-soft-delete-policy.\n",
      "\n",
      "✓ Job submitted! Monitor at:\n",
      "https://console.cloud.google.com/dataflow/jobs/us-central1?project=openbook-ml-demo\n"
     ]
    }
   ],
   "source": [
    "# Submit pipeline to Dataflow service\n",
    "# Runs the Python script on Dataflow workers\n",
    "\n",
    "print(\"Submitting Dataflow job...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Download script locally and run with DataflowRunner\n",
    "!python dataflow_feature_pipeline.py \\\n",
    "    --runner=DataflowRunner \\\n",
    "    --project={PROJECT_ID} \\\n",
    "    --region={REGION} \\\n",
    "    --staging_location=gs://{BUCKET_NAME}/staging \\\n",
    "    --temp_location=gs://{BUCKET_NAME}/temp \\\n",
    "    --job_name=openbook-feature-engineering\n",
    "\n",
    "print(\"\\n✓ Job submitted! Monitor at:\")\n",
    "print(f\"https://console.cloud.google.com/dataflow/jobs/{REGION}?project={PROJECT_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dad05c51-0dc5-424f-9e23-35ba824f559b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOB_ID                                   NAME                          TYPE   CREATION_TIME        STATE  REGION\n",
      "2025-12-14_11_20_24-1872466375908897589  openbook-feature-engineering  Batch  2025-12-14 19:20:25  Done   us-central1\n"
     ]
    }
   ],
   "source": [
    "# Submit via gcloud dataflow flex-template or direct Python execution\n",
    "# First, check if job exists\n",
    "\n",
    "!gcloud dataflow jobs list --region={REGION} --project={PROJECT_ID} --limit=5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25b95e88-d986-457f-91e4-5550acc41fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://openbook-data-lake/processed/features/.keep\n",
      "gs://openbook-data-lake/processed/features/features-00000-of-00001.csv\n"
     ]
    }
   ],
   "source": [
    "# Check if processed features were created\n",
    "!gsutil ls gs://{BUCKET_NAME}/processed/features/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd417a96-964f-4953-b4a3-58fd86b43c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Processed 10,000 claims\n",
      "✓ 29 features created\n",
      "\n",
      "Feature columns:\n",
      "['claim_id', 'patient_id', 'procedure_code', 'procedure_cost', 'annual_maximum', 'remaining_maximum', 'deductible_remaining', 'coverage_ratio', 'months_enrolled', 'max_utilization', 'cost_to_max_ratio', 'deductible_applies', 'network_penalty', 'waiting_period_risk', 'is_preventive', 'is_basic', 'is_major', 'high_cost_procedure', 'is_ppo', 'is_dhmo', 'is_indemnity', 'carrier_delta_dental', 'carrier_cigna', 'carrier_aetna', 'carrier_metlife', 'carrier_guardian', 'expected_copay', 'copay_deviation', 'patient_copay']\n",
      "\n",
      "Sample data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>procedure_code</th>\n",
       "      <th>procedure_cost</th>\n",
       "      <th>annual_maximum</th>\n",
       "      <th>remaining_maximum</th>\n",
       "      <th>deductible_remaining</th>\n",
       "      <th>coverage_ratio</th>\n",
       "      <th>months_enrolled</th>\n",
       "      <th>max_utilization</th>\n",
       "      <th>...</th>\n",
       "      <th>is_dhmo</th>\n",
       "      <th>is_indemnity</th>\n",
       "      <th>carrier_delta_dental</th>\n",
       "      <th>carrier_cigna</th>\n",
       "      <th>carrier_aetna</th>\n",
       "      <th>carrier_metlife</th>\n",
       "      <th>carrier_guardian</th>\n",
       "      <th>expected_copay</th>\n",
       "      <th>copay_deviation</th>\n",
       "      <th>patient_copay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CLM_000001</td>\n",
       "      <td>PAT_0903</td>\n",
       "      <td>D7140</td>\n",
       "      <td>220.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1967.108220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.016446</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.720000</td>\n",
       "      <td>45.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CLM_000002</td>\n",
       "      <td>PAT_0091</td>\n",
       "      <td>D2391</td>\n",
       "      <td>195.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>540.450051</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>36</td>\n",
       "      <td>0.459550</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>102.700000</td>\n",
       "      <td>280.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CLM_000003</td>\n",
       "      <td>PAT_0414</td>\n",
       "      <td>D1110</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1440.043682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.039971</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3.960000</td>\n",
       "      <td>29.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CLM_000004</td>\n",
       "      <td>PAT_0650</td>\n",
       "      <td>D2950</td>\n",
       "      <td>385.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>999999.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118.930000</td>\n",
       "      <td>118.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CLM_000005</td>\n",
       "      <td>PAT_0499</td>\n",
       "      <td>D2950</td>\n",
       "      <td>385.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>999999.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>435.367331</td>\n",
       "      <td>435.367331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     claim_id patient_id procedure_code  procedure_cost  annual_maximum  \\\n",
       "0  CLM_000001   PAT_0903          D7140           220.0          2000.0   \n",
       "1  CLM_000002   PAT_0091          D2391           195.0          1000.0   \n",
       "2  CLM_000003   PAT_0414          D1110           130.0          1500.0   \n",
       "3  CLM_000004   PAT_0650          D2950           385.0             0.0   \n",
       "4  CLM_000005   PAT_0499          D2950           385.0             0.0   \n",
       "\n",
       "   remaining_maximum  deductible_remaining  coverage_ratio  months_enrolled  \\\n",
       "0        1967.108220                   0.0             0.8               12   \n",
       "1         540.450051                 100.0             0.6               36   \n",
       "2        1440.043682                   0.0             0.8               12   \n",
       "3      999999.000000                   0.0             1.0               24   \n",
       "4      999999.000000                   0.0             1.0               24   \n",
       "\n",
       "   max_utilization  ...  is_dhmo  is_indemnity  carrier_delta_dental  \\\n",
       "0         0.016446  ...        0             0                     1   \n",
       "1         0.459550  ...        0             0                     0   \n",
       "2         0.039971  ...        0             1                     0   \n",
       "3         0.000000  ...        1             0                     0   \n",
       "4         0.000000  ...        1             0                     0   \n",
       "\n",
       "   carrier_cigna  carrier_aetna  carrier_metlife  carrier_guardian  \\\n",
       "0              0              0                0                 0   \n",
       "1              0              1                0                 0   \n",
       "2              0              0                0                 1   \n",
       "3              1              0                0                 0   \n",
       "4              1              0                0                 0   \n",
       "\n",
       "   expected_copay  copay_deviation  patient_copay  \n",
       "0            44.0         1.720000      45.720000  \n",
       "1           178.0       102.700000     280.700000  \n",
       "2            26.0         3.960000      29.960000  \n",
       "3             0.0       118.930000     118.930000  \n",
       "4             0.0       435.367331     435.367331  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify processed features\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# Load processed features\n",
    "blob = bucket.blob('processed/features/features-00000-of-00001.csv')\n",
    "content = blob.download_as_text()\n",
    "features_df = pd.read_csv(StringIO(content))\n",
    "\n",
    "print(f\"✓ Processed {len(features_df):,} claims\")\n",
    "print(f\"✓ {len(features_df.columns)} features created\")\n",
    "print(\"\\nFeature columns:\")\n",
    "print(features_df.columns.tolist())\n",
    "print(\"\\nSample data:\")\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bae1975c-c617-4658-b687-e7d44ca5e8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 7,000 samples\n",
      "Val:   1,500 samples\n",
      "Test:  1,500 samples\n",
      "✓ Uploaded gs://openbook-data-lake/processed/features/train.csv\n",
      "✓ Uploaded gs://openbook-data-lake/processed/features/val.csv\n",
      "✓ Uploaded gs://openbook-data-lake/processed/features/test.csv\n",
      "\n",
      "✓ Feature engineering complete\n",
      "✓ 24 input features\n",
      "✓ Target: patient_copay\n"
     ]
    }
   ],
   "source": [
    "# Create train/validation/test splits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Features for model (excluding IDs and target)\n",
    "feature_cols = [\n",
    "    'procedure_cost', 'annual_maximum', 'remaining_maximum', 'deductible_remaining',\n",
    "    'coverage_ratio', 'months_enrolled', 'max_utilization', 'cost_to_max_ratio',\n",
    "    'deductible_applies', 'network_penalty', 'waiting_period_risk',\n",
    "    'is_preventive', 'is_basic', 'is_major', 'high_cost_procedure',\n",
    "    'is_ppo', 'is_dhmo', 'is_indemnity',\n",
    "    'carrier_delta_dental', 'carrier_cigna', 'carrier_aetna', \n",
    "    'carrier_metlife', 'carrier_guardian',\n",
    "    'expected_copay'\n",
    "]\n",
    "\n",
    "target_col = 'patient_copay'\n",
    "id_cols = ['claim_id', 'patient_id', 'procedure_code']\n",
    "\n",
    "# Split: 70% train, 15% val, 15% test\n",
    "train_df, temp_df = train_test_split(features_df, test_size=0.3, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"Train: {len(train_df):,} samples\")\n",
    "print(f\"Val:   {len(val_df):,} samples\")\n",
    "print(f\"Test:  {len(test_df):,} samples\")\n",
    "\n",
    "# Upload splits to GCS\n",
    "for name, df in [('train', train_df), ('val', val_df), ('test', test_df)]:\n",
    "    blob = bucket.blob(f'processed/features/{name}.csv')\n",
    "    blob.upload_from_string(df.to_csv(index=False))\n",
    "    print(f\"✓ Uploaded gs://{BUCKET_NAME}/processed/features/{name}.csv\")\n",
    "\n",
    "print(f\"\\n✓ Feature engineering complete\")\n",
    "print(f\"✓ {len(feature_cols)} input features\")\n",
    "print(f\"✓ Target: {target_col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d36118-1799-442c-b492-a0e5818761a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m137",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m137"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
